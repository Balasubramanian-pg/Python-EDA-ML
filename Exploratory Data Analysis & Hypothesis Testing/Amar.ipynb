{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the data\n",
    "# Replace 'your_data.csv' with the actual path to your dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\balas\\Pictures\\Amar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Timestamp                 Name Gender    Age  \\\n",
      "0  2023/11/10 10:50:13 PM GMT+5:30  Ninte achante achar   Male  18-25   \n",
      "1                              NaN                  NaN    NaN    NaN   \n",
      "2                              NaN                  NaN    NaN    NaN   \n",
      "3                              NaN                  NaN    NaN    NaN   \n",
      "4                              NaN                  NaN    NaN    NaN   \n",
      "\n",
      "   Education Level            Current Occupation  Innovation_techno  \\\n",
      "0  Master's Degree  I identify myself as a donut  Strongly Disagree   \n",
      "1              NaN                           NaN           Disagree   \n",
      "2              NaN                           NaN            Neutral   \n",
      "3              NaN                           NaN              Agree   \n",
      "4              NaN                           NaN     Strongly Agree   \n",
      "\n",
      "             Mkt_stg Reg_chllng Cybersecurity_challenges  ... Sec_measures  \\\n",
      "0  Strongly Disagree        Yes                     Poor  ...         Poor   \n",
      "1           Disagree         No                     Fair  ...         Fair   \n",
      "2            Neutral        Yes                     Good  ...         Good   \n",
      "3              Agree         No                Very Good  ...    Very Good   \n",
      "4     Strongly Agree        Yes                Excellent  ...    Excellent   \n",
      "\n",
      "        Recomm access_to_finserv competitor   familiar_ind  \\\n",
      "0   Not Likely     Not Important        Yes    Never Heard   \n",
      "1  Less Likely    Less Important         No    Heard of it   \n",
      "2      Neutral         Important        Yes        Neutral   \n",
      "3  More Likely    More Important         No       Familiar   \n",
      "4  Very Likely    Very Important        Yes  Very Familiar   \n",
      "\n",
      "                               fintech_adoption  \\\n",
      "0                       Higher Trust in FinTech   \n",
      "1  Equal Trust in FinTech and Traditional Banks   \n",
      "2                        Lower Trust in FinTech   \n",
      "3                                      Not Sure   \n",
      "4                       Higher Trust in FinTech   \n",
      "\n",
      "                                      trust_lvl             fut_growth  \\\n",
      "0                       Higher Trust in FinTech        Very Optimistic   \n",
      "1  Equal Trust in FinTech and Traditional Banks  Moderatley Optimistic   \n",
      "2                        Lower Trust in FinTech                Neutral   \n",
      "3                                      Not Sure  Somewhat Pessismistic   \n",
      "4                       Higher Trust in FinTech       Very Pessimistic   \n",
      "\n",
      "                                   reg_env              suggestions  \n",
      "0       Conducive to Innovation and Growth  Hire only south Indians  \n",
      "1      Contains Some Regulatory Challenges                      NaN  \n",
      "2  Poses Significant Regulatory Challenges                      NaN  \n",
      "3       Conducive to Innovation and Growth                      NaN  \n",
      "4      Contains Some Regulatory Challenges                      NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 26 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Timestamp                 1 non-null      object\n",
      " 1   Name                      1 non-null      object\n",
      " 2   Gender                    1 non-null      object\n",
      " 3   Age                       1 non-null      object\n",
      " 4   Education Level           1 non-null      object\n",
      " 5   Current Occupation        1 non-null      object\n",
      " 6   Innovation_techno         134 non-null    object\n",
      " 7   Mkt_stg                   134 non-null    object\n",
      " 8   Reg_chllng                134 non-null    object\n",
      " 9   Cybersecurity_challenges  134 non-null    object\n",
      " 10  cmpt_lndscpe              134 non-null    object\n",
      " 11  lcl_economy               134 non-null    object\n",
      " 12  unbanked_underbanked      134 non-null    object\n",
      " 13  local_reg_policies        133 non-null    object\n",
      " 14  satisfy                   134 non-null    object\n",
      " 15  freq                      134 non-null    object\n",
      " 16  Sec_measures              134 non-null    object\n",
      " 17  Recomm                    134 non-null    object\n",
      " 18  access_to_finserv         134 non-null    object\n",
      " 19  competitor                134 non-null    object\n",
      " 20  familiar_ind              134 non-null    object\n",
      " 21  fintech_adoption          134 non-null    object\n",
      " 22  trust_lvl                 134 non-null    object\n",
      " 23  fut_growth                134 non-null    object\n",
      " 24  reg_env                   134 non-null    object\n",
      " 25  suggestions               1 non-null      object\n",
      "dtypes: object(26)\n",
      "memory usage: 27.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check basic information about the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Timestamp                 Name Gender    Age  \\\n",
      "count                                 1                    1      1      1   \n",
      "unique                                1                    1      1      1   \n",
      "top     2023/11/10 10:50:13 PM GMT+5:30  Ninte achante achar   Male  18-25   \n",
      "freq                                  1                    1      1      1   \n",
      "\n",
      "        Education Level            Current Occupation  Innovation_techno  \\\n",
      "count                 1                             1                134   \n",
      "unique                1                             1                  5   \n",
      "top     Master's Degree  I identify myself as a donut  Strongly Disagree   \n",
      "freq                  1                             1                 27   \n",
      "\n",
      "                  Mkt_stg Reg_chllng Cybersecurity_challenges  ...  \\\n",
      "count                 134        134                      134  ...   \n",
      "unique                  5          2                        5  ...   \n",
      "top     Strongly Disagree        Yes                     Poor  ...   \n",
      "freq                   27         80                       27  ...   \n",
      "\n",
      "       Sec_measures      Recomm access_to_finserv competitor familiar_ind  \\\n",
      "count           134         134               134        134          134   \n",
      "unique            5           5                 5          2            5   \n",
      "top            Poor  Not Likely     Not Important        Yes  Never Heard   \n",
      "freq             27          27                27         67           27   \n",
      "\n",
      "               fintech_adoption                trust_lvl       fut_growth  \\\n",
      "count                       134                      134              134   \n",
      "unique                        4                        4                5   \n",
      "top     Higher Trust in FinTech  Higher Trust in FinTech  Very Optimistic   \n",
      "freq                         34                       34               27   \n",
      "\n",
      "                                   reg_env              suggestions  \n",
      "count                                  134                        1  \n",
      "unique                                   3                        1  \n",
      "top     Conducive to Innovation and Growth  Hire only south Indians  \n",
      "freq                                    45                        1  \n",
      "\n",
      "[4 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Check summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                   133\n",
      "Name                        133\n",
      "Gender                      133\n",
      "Age                         133\n",
      "Education Level             133\n",
      "Current Occupation          133\n",
      "Innovation_techno             0\n",
      "Mkt_stg                       0\n",
      "Reg_chllng                    0\n",
      "Cybersecurity_challenges      0\n",
      "cmpt_lndscpe                  0\n",
      "lcl_economy                   0\n",
      "unbanked_underbanked          0\n",
      "local_reg_policies            1\n",
      "satisfy                       0\n",
      "freq                          0\n",
      "Sec_measures                  0\n",
      "Recomm                        0\n",
      "access_to_finserv             0\n",
      "competitor                    0\n",
      "familiar_ind                  0\n",
      "fintech_adoption              0\n",
      "trust_lvl                     0\n",
      "fut_growth                    0\n",
      "reg_env                       0\n",
      "suggestions                 133\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (134, 26)\n",
      "Data types of each column:\n",
      " Timestamp                   object\n",
      "Name                        object\n",
      "Gender                      object\n",
      "Age                         object\n",
      "Education Level             object\n",
      "Current Occupation          object\n",
      "Innovation_techno           object\n",
      "Mkt_stg                     object\n",
      "Reg_chllng                  object\n",
      "Cybersecurity_challenges    object\n",
      "cmpt_lndscpe                object\n",
      "lcl_economy                 object\n",
      "unbanked_underbanked        object\n",
      "local_reg_policies          object\n",
      "satisfy                     object\n",
      "freq                        object\n",
      "Sec_measures                object\n",
      "Recomm                      object\n",
      "access_to_finserv           object\n",
      "competitor                  object\n",
      "familiar_ind                object\n",
      "fintech_adoption            object\n",
      "trust_lvl                   object\n",
      "fut_growth                  object\n",
      "reg_env                     object\n",
      "suggestions                 object\n",
      "dtype: object\n",
      "Missing values:\n",
      " Timestamp                   133\n",
      "Name                        133\n",
      "Gender                      133\n",
      "Age                         133\n",
      "Education Level             133\n",
      "Current Occupation          133\n",
      "Innovation_techno             0\n",
      "Mkt_stg                       0\n",
      "Reg_chllng                    0\n",
      "Cybersecurity_challenges      0\n",
      "cmpt_lndscpe                  0\n",
      "lcl_economy                   0\n",
      "unbanked_underbanked          0\n",
      "local_reg_policies            1\n",
      "satisfy                       0\n",
      "freq                          0\n",
      "Sec_measures                  0\n",
      "Recomm                        0\n",
      "access_to_finserv             0\n",
      "competitor                    0\n",
      "familiar_ind                  0\n",
      "fintech_adoption              0\n",
      "trust_lvl                     0\n",
      "fut_growth                    0\n",
      "reg_env                       0\n",
      "suggestions                 133\n",
      "dtype: int64\n",
      "Distribution of Timestamp:\n",
      " 2023/11/10 10:50:13 PM GMT+5:30    1\n",
      "Name: Timestamp, dtype: int64 \n",
      "\n",
      "Distribution of Name:\n",
      " Ninte achante achar    1\n",
      "Name: Name, dtype: int64 \n",
      "\n",
      "Distribution of Gender:\n",
      " Male    1\n",
      "Name: Gender, dtype: int64 \n",
      "\n",
      "Distribution of Age:\n",
      " 18-25    1\n",
      "Name: Age, dtype: int64 \n",
      "\n",
      "Distribution of Education Level:\n",
      " Master's Degree    1\n",
      "Name: Education Level, dtype: int64 \n",
      "\n",
      "Distribution of Current Occupation:\n",
      " I identify myself as a donut    1\n",
      "Name: Current Occupation, dtype: int64 \n",
      "\n",
      "Distribution of Innovation_techno:\n",
      " Strongly Disagree    27\n",
      "Disagree             27\n",
      "Neutral              27\n",
      "Agree                27\n",
      "Strongly Agree       26\n",
      "Name: Innovation_techno, dtype: int64 \n",
      "\n",
      "Distribution of Mkt_stg:\n",
      " Strongly Disagree    27\n",
      "Disagree             27\n",
      "Neutral              27\n",
      "Agree                27\n",
      "Strongly Agree       26\n",
      "Name: Mkt_stg, dtype: int64 \n",
      "\n",
      "Distribution of Reg_chllng:\n",
      " Yes    80\n",
      "No     54\n",
      "Name: Reg_chllng, dtype: int64 \n",
      "\n",
      "Distribution of Cybersecurity_challenges:\n",
      " Poor         27\n",
      "Fair         27\n",
      "Good         27\n",
      "Very Good    27\n",
      "Excellent    26\n",
      "Name: Cybersecurity_challenges, dtype: int64 \n",
      "\n",
      "Distribution of cmpt_lndscpe:\n",
      " Yes    68\n",
      "No     66\n",
      "Name: cmpt_lndscpe, dtype: int64 \n",
      "\n",
      "Distribution of lcl_economy:\n",
      " Significantly    53\n",
      "Moderately       27\n",
      "Slightly         27\n",
      "Not at all       27\n",
      "Name: lcl_economy, dtype: int64 \n",
      "\n",
      "Distribution of unbanked_underbanked:\n",
      " Strongly Disagree    27\n",
      "Disagree             27\n",
      "Neutral              27\n",
      "Agree                27\n",
      "Strongly Agree       26\n",
      "Name: unbanked_underbanked, dtype: int64 \n",
      "\n",
      "Distribution of local_reg_policies:\n",
      " Yes    67\n",
      "No     66\n",
      "Name: local_reg_policies, dtype: int64 \n",
      "\n",
      "Distribution of satisfy:\n",
      " Dissatisfied         54\n",
      "Very Dissatisfied    27\n",
      "Neutral              27\n",
      "Very Satisfied       26\n",
      "Name: satisfy, dtype: int64 \n",
      "\n",
      "Distribution of freq:\n",
      " Daily        27\n",
      "Weekly       27\n",
      "Monthly      27\n",
      "Quarterly    27\n",
      "Yearly       26\n",
      "Name: freq, dtype: int64 \n",
      "\n",
      "Distribution of Sec_measures:\n",
      " Poor         27\n",
      "Fair         27\n",
      "Good         27\n",
      "Very Good    27\n",
      "Excellent    26\n",
      "Name: Sec_measures, dtype: int64 \n",
      "\n",
      "Distribution of Recomm:\n",
      " Not Likely     27\n",
      "Less Likely    27\n",
      "Neutral        27\n",
      "More Likely    27\n",
      "Very Likely    26\n",
      "Name: Recomm, dtype: int64 \n",
      "\n",
      "Distribution of access_to_finserv:\n",
      " Not Important     27\n",
      "Less Important    27\n",
      "Important         27\n",
      "More Important    27\n",
      "Very Important    26\n",
      "Name: access_to_finserv, dtype: int64 \n",
      "\n",
      "Distribution of competitor:\n",
      " Yes    67\n",
      "No     67\n",
      "Name: competitor, dtype: int64 \n",
      "\n",
      "Distribution of familiar_ind:\n",
      " Never Heard      27\n",
      "Heard of it      27\n",
      "Neutral          27\n",
      "Familiar         27\n",
      "Very Familiar    26\n",
      "Name: familiar_ind, dtype: int64 \n",
      "\n",
      "Distribution of fintech_adoption:\n",
      " Higher Trust in FinTech                         34\n",
      "Equal Trust in FinTech and Traditional Banks    34\n",
      "Lower Trust in FinTech                          33\n",
      "Not Sure                                        33\n",
      "Name: fintech_adoption, dtype: int64 \n",
      "\n",
      "Distribution of trust_lvl:\n",
      " Higher Trust in FinTech                         34\n",
      "Equal Trust in FinTech and Traditional Banks    34\n",
      "Lower Trust in FinTech                          33\n",
      "Not Sure                                        33\n",
      "Name: trust_lvl, dtype: int64 \n",
      "\n",
      "Distribution of fut_growth:\n",
      " Very Optimistic          27\n",
      "Moderatley Optimistic    27\n",
      "Neutral                  27\n",
      "Somewhat Pessismistic    27\n",
      "Very Pessimistic         26\n",
      "Name: fut_growth, dtype: int64 \n",
      "\n",
      "Distribution of reg_env:\n",
      " Conducive to Innovation and Growth         45\n",
      "Contains Some Regulatory Challenges        45\n",
      "Poses Significant Regulatory Challenges    44\n",
      "Name: reg_env, dtype: int64 \n",
      "\n",
      "Distribution of suggestions:\n",
      " Hire only south Indians    1\n",
      "Name: suggestions, dtype: int64 \n",
      "\n",
      "Range of values for each numerical variable:\n",
      "      Innovation_techno            Mkt_stg Reg_chllng Cybersecurity_challenges  \\\n",
      "min              Agree              Agree         No                Excellent   \n",
      "max  Strongly Disagree  Strongly Disagree        Yes                Very Good   \n",
      "\n",
      "    cmpt_lndscpe lcl_economy unbanked_underbanked         satisfy    freq  \\\n",
      "min           No  Moderately                Agree    Dissatisfied   Daily   \n",
      "max          Yes    Slightly    Strongly Disagree  Very Satisfied  Yearly   \n",
      "\n",
      "    Sec_measures       Recomm access_to_finserv competitor   familiar_ind  \\\n",
      "min    Excellent  Less Likely         Important         No       Familiar   \n",
      "max    Very Good  Very Likely    Very Important        Yes  Very Familiar   \n",
      "\n",
      "                                 fintech_adoption  \\\n",
      "min  Equal Trust in FinTech and Traditional Banks   \n",
      "max                                      Not Sure   \n",
      "\n",
      "                                        trust_lvl             fut_growth  \\\n",
      "min  Equal Trust in FinTech and Traditional Banks  Moderatley Optimistic   \n",
      "max                                      Not Sure       Very Pessimistic   \n",
      "\n",
      "                                     reg_env  \n",
      "min       Conducive to Innovation and Growth  \n",
      "max  Poses Significant Regulatory Challenges  \n",
      "Correlation Matrix:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Number of unique values in each categorical variable:\n",
      " Timestamp                   1\n",
      "Name                        1\n",
      "Gender                      1\n",
      "Age                         1\n",
      "Education Level             1\n",
      "Current Occupation          1\n",
      "Innovation_techno           5\n",
      "Mkt_stg                     5\n",
      "Reg_chllng                  2\n",
      "Cybersecurity_challenges    5\n",
      "cmpt_lndscpe                2\n",
      "lcl_economy                 4\n",
      "unbanked_underbanked        5\n",
      "local_reg_policies          2\n",
      "satisfy                     4\n",
      "freq                        5\n",
      "Sec_measures                5\n",
      "Recomm                      5\n",
      "access_to_finserv           5\n",
      "competitor                  2\n",
      "familiar_ind                5\n",
      "fintech_adoption            4\n",
      "trust_lvl                   4\n",
      "fut_growth                  5\n",
      "reg_env                     3\n",
      "suggestions                 1\n",
      "dtype: int64\n",
      "Most frequent response for Timestamp: 2023/11/10 10:50:13 PM GMT+5:30\n",
      "Most frequent response for Name: Ninte achante achar\n",
      "Most frequent response for Gender: Male\n",
      "Most frequent response for Age: 18-25\n",
      "Most frequent response for Education Level: Master's Degree\n",
      "Most frequent response for Current Occupation: I identify myself as a donut\n",
      "Most frequent response for Innovation_techno: Agree\n",
      "Most frequent response for Mkt_stg: Agree\n",
      "Most frequent response for Reg_chllng: Yes\n",
      "Most frequent response for Cybersecurity_challenges: Fair\n",
      "Most frequent response for cmpt_lndscpe: Yes\n",
      "Most frequent response for lcl_economy: Significantly\n",
      "Most frequent response for unbanked_underbanked: Agree\n",
      "Most frequent response for local_reg_policies: Yes\n",
      "Most frequent response for satisfy: Dissatisfied\n",
      "Most frequent response for freq: Daily\n",
      "Most frequent response for Sec_measures: Fair\n",
      "Most frequent response for Recomm: Less Likely\n",
      "Most frequent response for access_to_finserv: Important\n",
      "Most frequent response for competitor: No\n",
      "Most frequent response for familiar_ind: Familiar\n",
      "Most frequent response for fintech_adoption: Equal Trust in FinTech and Traditional Banks\n",
      "Most frequent response for trust_lvl: Equal Trust in FinTech and Traditional Banks\n",
      "Most frequent response for fut_growth: Moderatley Optimistic\n",
      "Most frequent response for reg_env: Conducive to Innovation and Growth\n",
      "Most frequent response for suggestions: Hire only south Indians\n",
      "Satisfaction with frequency of accessing financial services:\n",
      " Daily        27\n",
      "Weekly       27\n",
      "Monthly      27\n",
      "Quarterly    27\n",
      "Yearly       26\n",
      "Name: freq, dtype: int64\n",
      "Satisfaction with cybersecurity measures:\n",
      " Poor         27\n",
      "Fair         27\n",
      "Good         27\n",
      "Very Good    27\n",
      "Excellent    26\n",
      "Name: Sec_measures, dtype: int64\n",
      "Frequency of encountering local regulatory challenges:\n",
      " Significantly    53\n",
      "Moderately       27\n",
      "Slightly         27\n",
      "Not at all       27\n",
      "Name: lcl_economy, dtype: int64\n",
      "Trust in FinTech compared to traditional banks:\n",
      " Higher Trust in FinTech                         34\n",
      "Equal Trust in FinTech and Traditional Banks    34\n",
      "Lower Trust in FinTech                          33\n",
      "Not Sure                                        33\n",
      "Name: trust_lvl, dtype: int64\n",
      "Optimism about the future growth of the fintech sector:\n",
      " Very Optimistic          27\n",
      "Moderatley Optimistic    27\n",
      "Neutral                  27\n",
      "Somewhat Pessismistic    27\n",
      "Very Pessimistic         26\n",
      "Name: fut_growth, dtype: int64\n",
      "Sentiment towards the regulatory environment:\n",
      " Conducive to Innovation and Growth         45\n",
      "Contains Some Regulatory Challenges        45\n",
      "Poses Significant Regulatory Challenges    44\n",
      "Name: reg_env, dtype: int64\n",
      "Specific suggestions mentioned in the dataset:\n",
      " ['Hire only south Indians' nan]\n",
      "Impact of the local economy on views on innovation:\n",
      " lcl_economy    Innovation_techno\n",
      "Moderately     Disagree             27\n",
      "Not at all     Agree                27\n",
      "Significantly  Strongly Disagree    27\n",
      "               Strongly Agree       26\n",
      "Slightly       Neutral              27\n",
      "Name: Innovation_techno, dtype: int64\n",
      "Relationship between being unbanked/underbanked and trust in FinTech:\n",
      " unbanked_underbanked  trust_lvl                                   \n",
      "Agree                 Equal Trust in FinTech and Traditional Banks    7\n",
      "                      Higher Trust in FinTech                         7\n",
      "                      Not Sure                                        7\n",
      "                      Lower Trust in FinTech                          6\n",
      "Disagree              Equal Trust in FinTech and Traditional Banks    7\n",
      "                      Lower Trust in FinTech                          7\n",
      "                      Not Sure                                        7\n",
      "                      Higher Trust in FinTech                         6\n",
      "Neutral               Higher Trust in FinTech                         7\n",
      "                      Lower Trust in FinTech                          7\n",
      "                      Not Sure                                        7\n",
      "                      Equal Trust in FinTech and Traditional Banks    6\n",
      "Strongly Agree        Equal Trust in FinTech and Traditional Banks    7\n",
      "                      Higher Trust in FinTech                         7\n",
      "                      Lower Trust in FinTech                          6\n",
      "                      Not Sure                                        6\n",
      "Strongly Disagree     Equal Trust in FinTech and Traditional Banks    7\n",
      "                      Higher Trust in FinTech                         7\n",
      "                      Lower Trust in FinTech                          7\n",
      "                      Not Sure                                        6\n",
      "Name: trust_lvl, dtype: int64\n",
      "Familiarity with the fintech industry:\n",
      " Never Heard      27\n",
      "Heard of it      27\n",
      "Neutral          27\n",
      "Familiar         27\n",
      "Very Familiar    26\n",
      "Name: familiar_ind, dtype: int64\n",
      "Effect of regional challenge on perception of the regulatory environment:\n",
      " Reg_chllng  reg_env                                \n",
      "No          Conducive to Innovation and Growth         18\n",
      "            Contains Some Regulatory Challenges        18\n",
      "            Poses Significant Regulatory Challenges    18\n",
      "Yes         Conducive to Innovation and Growth         27\n",
      "            Contains Some Regulatory Challenges        27\n",
      "            Poses Significant Regulatory Challenges    26\n",
      "Name: reg_env, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balas\\AppData\\Local\\Temp\\ipykernel_24060\\3226182808.py:15: FutureWarning: ['Timestamp', 'Name', 'Gender', 'Age', 'Education Level', 'Current Occupation', 'local_reg_policies', 'suggestions'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  print(\"Range of values for each numerical variable:\\n\", df.agg(['min', 'max']))\n",
      "C:\\Users\\balas\\AppData\\Local\\Temp\\ipykernel_24060\\3226182808.py:25: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = df.corr()\n"
     ]
    }
   ],
   "source": [
    "# 1. What is the overall structure of the dataset (number of rows and columns)?\n",
    "print(\"Number of rows and columns:\", df.shape)\n",
    "\n",
    "# 2. What are the data types of each column?\n",
    "print(\"Data types of each column:\\n\", df.dtypes)\n",
    "\n",
    "# 3. Are there any missing values in the dataset?\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# 4. What is the distribution of responses for each categorical variable?\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"Distribution of {column}:\\n\", df[column].value_counts(), \"\\n\")\n",
    "\n",
    "# 5. What is the range of values for each numerical variable?\n",
    "print(\"Range of values for each numerical variable:\\n\", df.agg(['min', 'max']))\n",
    "\n",
    "# 6. How is the data distributed for each numerical variable?\n",
    "for column in df.select_dtypes(include='number').columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(df[column], kde=True, color='skyblue')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n",
    "\n",
    "# 7. Is there a correlation between any of the numerical variables?\n",
    "correlation_matrix = df.corr()\n",
    "print(\"Correlation Matrix:\\n\", correlation_matrix)\n",
    "\n",
    "# 8. How many unique values are there in each categorical variable?\n",
    "print(\"Number of unique values in each categorical variable:\\n\", df.select_dtypes(include='object').nunique())\n",
    "\n",
    "# 9. What is the most frequent response for each categorical variable?\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"Most frequent response for {column}:\", df[column].mode().values[0])\n",
    "\n",
    "# 10. How satisfied are respondents with the frequency of accessing financial services?\n",
    "print(\"Satisfaction with frequency of accessing financial services:\\n\", df['freq'].value_counts())\n",
    "\n",
    "# 11. What is the level of satisfaction with cybersecurity measures?\n",
    "print(\"Satisfaction with cybersecurity measures:\\n\", df['Sec_measures'].value_counts())\n",
    "\n",
    "# 12. How frequently do respondents encounter local regulatory challenges?\n",
    "print(\"Frequency of encountering local regulatory challenges:\\n\", df['lcl_economy'].value_counts())\n",
    "\n",
    "# 13. What is the level of trust in FinTech compared to traditional banks?\n",
    "print(\"Trust in FinTech compared to traditional banks:\\n\", df['trust_lvl'].value_counts())\n",
    "\n",
    "# 14. How optimistic are respondents about the future growth of the fintech sector?\n",
    "print(\"Optimism about the future growth of the fintech sector:\\n\", df['fut_growth'].value_counts())\n",
    "\n",
    "# 15. What is the general sentiment towards the regulatory environment?\n",
    "print(\"Sentiment towards the regulatory environment:\\n\", df['reg_env'].value_counts())\n",
    "\n",
    "# 16. Are there any specific suggestions mentioned in the dataset?\n",
    "print(\"Specific suggestions mentioned in the dataset:\\n\", df['suggestions'].unique())\n",
    "\n",
    "# 17. How does the local economy impact respondents' views on innovation?\n",
    "print(\"Impact of the local economy on views on innovation:\\n\", df.groupby('lcl_economy')['Innovation_techno'].value_counts())\n",
    "\n",
    "# 18. Is there a relationship between being unbanked/underbanked and trust in FinTech?\n",
    "print(\"Relationship between being unbanked/underbanked and trust in FinTech:\\n\", df.groupby('unbanked_underbanked')['trust_lvl'].value_counts())\n",
    "\n",
    "# 19. What is the level of familiarity with the fintech industry among respondents?\n",
    "print(\"Familiarity with the fintech industry:\\n\", df['familiar_ind'].value_counts())\n",
    "\n",
    "# 20. How does the regional challenge affect the perception of the regulatory environment?\n",
    "print(\"Effect of regional challenge on perception of the regulatory environment:\\n\", df.groupby('Reg_chllng')['reg_env'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Disagree'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32ma:\\Semester 4\\1.Dissertation\\Analysis and Interpretation\\Amar.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Semester%204/1.Dissertation/Analysis%20and%20Interpretation/Amar.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Semester%204/1.Dissertation/Analysis%20and%20Interpretation/Amar.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Fit the model on the training data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/a%3A/Semester%204/1.Dissertation/Analysis%20and%20Interpretation/Amar.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Semester%204/1.Dissertation/Analysis%20and%20Interpretation/Amar.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Semester%204/1.Dissertation/Analysis%20and%20Interpretation/Amar.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\balas\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39maccept_sparse, y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    650\u001b[0m )\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\balas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\balas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\balas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype, xp\u001b[39m=\u001b[39mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\balas\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\balas\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Disagree'"
     ]
    }
   ],
   "source": [
    "# Step 13: Regression Analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set 'Reg_chllng' as the dependent variable\n",
    "dependent_variable = 'Reg_chllng'\n",
    "\n",
    "# Specify the independent variables\n",
    "independent_variables = ['Innovation_techno', 'Mkt_stg', 'Cybersecurity_challenges', 'cmpt_lndscpe',\n",
    "                          'lcl_economy', 'unbanked_underbanked', 'local_reg_policies', 'satisfy',\n",
    "                          'freq', 'Sec_measures', 'Recomm', 'access_to_finserv', 'competitor',\n",
    "                          'familiar_ind', 'fintech_adoption', 'trust_lvl', 'fut_growth', 'reg_env']\n",
    "\n",
    "# Select the columns for regression analysis\n",
    "X = df[independent_variables]\n",
    "y = df[dependent_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 14: Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Optional: Print the coefficients of the model\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared value: 12.976299812257752\n",
      "P-value: 0.00031545878127294696\n",
      "Cramér's V statistic: 2.547184702005113\n",
      "\n",
      "Interpretation:\n",
      "Significance level: 0.05\n",
      "P-value: 0.00031545878127294696\n",
      "Reject the null hypothesis (There is a significant relationship between the variables)\n",
      "\n",
      "Cramér's V Interpretation:\n",
      "A Cramér's V value of 0 indicates no association, and 1 indicates a strong association.\n",
      "Cramér's V: 2.547184702005113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset (replace 'your_dataset.xlsx' with the actual file name)\n",
    "df = pd.read_csv(r\"C:\\Users\\balas\\Pictures\\Amar.csv\")\n",
    "\n",
    "# Choose two categorical variables for analysis\n",
    "variable1 = 'Reg_chllng'\n",
    "variable2 = 'local_reg_policies'\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[variable1], df[variable2])\n",
    "\n",
    "# Perform Chi-squared test for independence\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Calculate Cramér's V statistic\n",
    "num_rows = contingency_table.shape[0]\n",
    "num_columns = contingency_table.shape[1]\n",
    "cramers_v = np.sqrt(chi2 / (num_rows * (min(num_columns, num_rows) - 1)))\n",
    "\n",
    "# Print results\n",
    "print(f\"Chi-squared value: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Cramér's V statistic: {cramers_v}\")\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"Significance level: {alpha}\")\n",
    "print(f\"P-value: {p}\")\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis (There is a significant relationship between the variables)\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis (There is no significant relationship between the variables)\")\n",
    "\n",
    "# Cramér's V interpretation\n",
    "print(\"\\nCramér's V Interpretation:\")\n",
    "print(f\"A Cramér's V value of 0 indicates no association, and 1 indicates a strong association.\")\n",
    "print(f\"Cramér's V: {cramers_v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared value: 8.630668236164732\n",
      "P-value: 0.003305502985707573\n",
      "Cramér's V statistic: 2.0773382291004916\n",
      "\n",
      "Interpretation:\n",
      "Significance level: 0.05\n",
      "P-value: 0.003305502985707573\n",
      "Reject the null hypothesis (There is a significant relationship between the variables)\n",
      "\n",
      "Cramér's V Interpretation:\n",
      "A Cramér's V value of 0 indicates no association, and 1 indicates a strong association.\n",
      "Cramér's V: 2.0773382291004916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset (replace 'your_dataset.xlsx' with the actual file name)\n",
    "df = pd.read_csv(r\"C:\\Users\\balas\\Pictures\\Amar.csv\")\n",
    "\n",
    "# Choose two categorical variables for analysis\n",
    "variable1 = 'competitor'\n",
    "variable2 = 'cmpt_lndscpe'\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[variable1], df[variable2])\n",
    "\n",
    "# Perform Chi-squared test for independence\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Calculate Cramér's V statistic\n",
    "num_rows = contingency_table.shape[0]\n",
    "num_columns = contingency_table.shape[1]\n",
    "cramers_v = np.sqrt(chi2 / (num_rows * (min(num_columns, num_rows) - 1)))\n",
    "\n",
    "# Print results\n",
    "print(f\"Chi-squared value: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Cramér's V statistic: {cramers_v}\")\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"Significance level: {alpha}\")\n",
    "print(f\"P-value: {p}\")\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis (There is a significant relationship between the variables)\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis (There is no significant relationship between the variables)\")\n",
    "\n",
    "# Cramér's V interpretation\n",
    "print(\"\\nCramér's V Interpretation:\")\n",
    "print(f\"A Cramér's V value of 0 indicates no association, and 1 indicates a strong association.\")\n",
    "print(f\"Cramér's V: {cramers_v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
