{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HAR file\n",
    "with open(r\"C:\\Users\\ASUS\\Downloads\\www.linkedin.com_Archive [24-07-28 19-05-02].har\", encoding='utf-8') as file:\n",
    "    har_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate through the HAR file entries\n",
    "for entry in har_data['log']['entries']:\n",
    "    # Check if the request URL contains 'linkedin.com'\n",
    "    if 'linkedin.com' in entry['request']['url']:\n",
    "        # Access the response content\n",
    "        response_content = entry['response'].get('content', {})\n",
    "        \n",
    "        # Check if 'text' key is present in the response content\n",
    "        if 'text' in response_content:\n",
    "            response = response_content['text']\n",
    "            try:\n",
    "                # Convert the response content to a dictionary\n",
    "                response_data = json.loads(response)\n",
    "                \n",
    "                # Check if the profiles key exists in the response data\n",
    "                if 'profiles' in response_data:\n",
    "                    # Extract relevant information\n",
    "                    for profile in response_data['profiles']:\n",
    "                        name = profile.get('name')\n",
    "                        url = profile.get('url')\n",
    "                        designation = profile.get('headline')\n",
    "                        company = profile.get('companyName')\n",
    "                        \n",
    "                        # Append the extracted data to the list\n",
    "                        extracted_data.append([name, url, designation, company])\n",
    "            except json.JSONDecodeError:\n",
    "                # Skip entries that are not valid JSON\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Saved to linkedin_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the CSV file path\n",
    "output_file = 'linkedin_data.csv'\n",
    "\n",
    "# Write the extracted data to the CSV file\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Name', 'URL', 'Designation', 'Company'])\n",
    "    # Write the data\n",
    "    writer.writerows(extracted_data)\n",
    "\n",
    "print(f\"Data extraction complete. Saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
